{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputations methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to explore different imputation methods\n",
    "\n",
    "For a more theoretical perspective consider http://www.stat.columbia.edu/~gelman/arm/missing.pdf\n",
    "\n",
    "In out case the missingness of values is not random but can be an indicator by itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define a little clearer the setting exactly. For startes we are going to deal with only the 5 most common diseases. Also for starters we are merely going to deal with classifying based on the first diagnosis given only. We are going to consider the multiclass classification problem first, but we are should also check the binary classification one to compare with established methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviour_data = pd.read_csv('DataScience2019_MRI/Behavioral/cleaned/HBNFinalSummaries.csv', low_memory=False)\n",
    "\n",
    "behaviour_data = behaviour_data[behaviour_data['NoDX'].isin(['Yes', 'No'])]\n",
    "\n",
    "keep_most_common_diseases = 5\n",
    "most_common_disorders = behaviour_data['DX_01_Cat'].value_counts().keys().values[:keep_most_common_diseases]\n",
    "behaviour_data = behaviour_data[behaviour_data['DX_01_Cat'].isin(most_common_disorders)]\n",
    "behaviour_data = behaviour_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neurodevelopmental Disorders', 'No Diagnosis Given',\n",
       "       'Anxiety Disorders', 'Depressive Disorders', 'Disruptive'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_disorders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.zeros((len(most_common_disorders), behaviour_data.shape[0]), dtype=np.int32)\n",
    "\n",
    "category_columns = ['DX_' + str(i).zfill(2) + '_Cat' for i in range(1, 11)]\n",
    "df_disorders = behaviour_data[category_columns]\n",
    "\n",
    "for i, disorder in enumerate(most_common_disorders):\n",
    "    mask = df_disorders.select_dtypes(include=[object]). \\\n",
    "            applymap(lambda x: disorder in x if pd.notnull(x) else False)\n",
    "    \n",
    "    disorder_df = df_disorders[mask.any(axis=1)]\n",
    "    \n",
    "    np.add.at(classes[i], disorder_df.index.values, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can safely remove previous columns describing diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviour_data_columns = behaviour_data.columns.values.astype(np.str)\n",
    "\n",
    "columns_to_drop = behaviour_data_columns[\n",
    "    np.flatnonzero(np.core.defchararray.find(behaviour_data_columns, 'DX')!=-1)]\n",
    "\n",
    "behaviour_data = behaviour_data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for disorder, classification in zip(most_common_disorders, classes):\n",
    "    behaviour_data[disorder] = classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also reasonable to assume that we need to drop columns with too many Nans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 0.8\n",
    "\n",
    "# columns_mask = pd.isnull(behaviour_data).sum() / behaviour_data.shape[0] > threshold\n",
    "\n",
    "# print('Droping this many columns:', np.sum(columns_mask))\n",
    "\n",
    "# dropped_columns = behaviour_data.columns[columns_mask]\n",
    "\n",
    "# behaviour_data = behaviour_data.drop(columns=dropped_columns)\n",
    "# behaviour_data = behaviour_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1725, 311)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anonymized.ID</th>\n",
       "      <th>EID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Study.Site</th>\n",
       "      <th>ACE_Score</th>\n",
       "      <th>APQ_P_OPD</th>\n",
       "      <th>APQ_P_Total</th>\n",
       "      <th>APQ_SR_OPD</th>\n",
       "      <th>APQ_SR_Total</th>\n",
       "      <th>...</th>\n",
       "      <th>YSR_RBB</th>\n",
       "      <th>YSR_SC</th>\n",
       "      <th>YSR_Ext</th>\n",
       "      <th>YSR_Int</th>\n",
       "      <th>YSR_Total</th>\n",
       "      <th>Neurodevelopmental Disorders</th>\n",
       "      <th>No Diagnosis Given</th>\n",
       "      <th>Anxiety Disorders</th>\n",
       "      <th>Depressive Disorders</th>\n",
       "      <th>Disruptive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A00078864</td>\n",
       "      <td>NDARYM832PX3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.048254</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A00078865</td>\n",
       "      <td>NDARNJ687DMC</td>\n",
       "      <td>1</td>\n",
       "      <td>6.348163</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A00078866</td>\n",
       "      <td>NDARRM363BXZ</td>\n",
       "      <td>0</td>\n",
       "      <td>10.052589</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A00078867</td>\n",
       "      <td>NDARUW586LLL</td>\n",
       "      <td>1</td>\n",
       "      <td>12.319415</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A00078868</td>\n",
       "      <td>NDARDC298NW4</td>\n",
       "      <td>0</td>\n",
       "      <td>13.901437</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 311 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Anonymized.ID           EID  Sex        Age  Study.Site  ACE_Score  \\\n",
       "0     A00078864  NDARYM832PX3    1   7.048254           1        NaN   \n",
       "1     A00078865  NDARNJ687DMC    1   6.348163           1        NaN   \n",
       "2     A00078866  NDARRM363BXZ    0  10.052589           1        NaN   \n",
       "3     A00078867  NDARUW586LLL    1  12.319415           1        NaN   \n",
       "4     A00078868  NDARDC298NW4    0  13.901437           1        NaN   \n",
       "\n",
       "   APQ_P_OPD  APQ_P_Total  APQ_SR_OPD  APQ_SR_Total  ...  YSR_RBB  YSR_SC  \\\n",
       "0        NaN          NaN         NaN           NaN  ...      NaN     NaN   \n",
       "1        NaN          NaN         NaN           NaN  ...      NaN     NaN   \n",
       "2        NaN          NaN        17.0         118.0  ...      NaN     NaN   \n",
       "3        NaN          NaN         NaN           NaN  ...      7.0     9.0   \n",
       "4        NaN          NaN        33.0         154.0  ...      2.0    11.0   \n",
       "\n",
       "   YSR_Ext  YSR_Int  YSR_Total  Neurodevelopmental Disorders  \\\n",
       "0      NaN      NaN        NaN                             1   \n",
       "1      NaN      NaN        NaN                             0   \n",
       "2      NaN      NaN        NaN                             1   \n",
       "3     16.0     29.0       85.0                             0   \n",
       "4     10.0     26.0       70.0                             1   \n",
       "\n",
       "   No Diagnosis Given  Anxiety Disorders  Depressive Disorders  Disruptive  \n",
       "0                   0                  1                     0           0  \n",
       "1                   0                  0                     1           0  \n",
       "2                   0                  0                     0           0  \n",
       "3                   0                  0                     1           0  \n",
       "4                   0                  0                     0           0  \n",
       "\n",
       "[5 rows x 311 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Shape', behaviour_data.shape)\n",
    "behaviour_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to explore some different imputation methods. More specifically:\n",
    "1. Do nothing\n",
    "2. Fill all missing values with a dummy value\n",
    "3. Imputation Using (Mean/Median/Most Frequent) Values\n",
    "4. Imputation Using k-NN\n",
    "5. \n",
    "6. Add features based on whether the value exists or not\n",
    "\n",
    "For a comparison with a more naive baseline check out @gvasilako 's notebook for both multilabel and per class metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xgboost as xgb\n",
    "from impyute.imputation.cs import fast_knn\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.exceptions import UndefinedMetricWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdx and mdx may contain 'No Diagnosis'\n",
    "# drop them for now but they may be important\n",
    "# they correspond to father's and mother's primary diagnosis\n",
    "columns_to_drop = ['Anonymized.ID', 'EID', 'mdx', 'fdx', 'fcodxm_1', 'fcodxm_2', 'fcodxm_3', 'mcodxm_1',\n",
    "                   'mcodxm_2', 'mcodxm_3', 'mcodxmdt', 'TOWRE_Total_Desc', 'Picture_Vocab_Raw',\n",
    "                   'sib1dx', 'sib1codxm_1', 'sib1codxm_2', 'sib1codxm_3',\n",
    "                   'sib2dx', 'sib2codxm_1', 'sib2codxm_2', 'sib2codxm_3',\n",
    "                   'sib3dx', 'sib3codxm_1', 'sib3codxm_2', 'sib3codxm_3',\n",
    "                   'sib4dx', 'sib4codxm_1', 'sib4codxm_2', 'sib4codxm_3',\n",
    "                   'sib5dx', 'sib5codxm_1', 'sib5codxm_2', 'sib5codxm_3']\n",
    "\n",
    "processed = behaviour_data.drop(columns=columns_to_drop)\n",
    "most_common_disorders = list(most_common_disorders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_binary_classification(dataset, diseases_to_run_for, clf, imputer, imputer_requires_disorder, *args):\n",
    "    for check_disorder in most_common_disorders[:diseases_to_run_for]:\n",
    "        \n",
    "        pos = most_common_disorders.index(check_disorder)\n",
    "\n",
    "        columns_to_drop = most_common_disorders[:pos] + most_common_disorders[(pos + 1):]\n",
    "        temp = dataset.drop(columns=columns_to_drop)\n",
    "\n",
    "        train, test = train_test_split(temp, test_size=0.3, random_state=17)\n",
    "        \n",
    "        if imputer_requires_disorder:\n",
    "            train, test = imputer(train, test, check_disorder, *args)\n",
    "        else:\n",
    "            train, test = imputer(train, test, *args)\n",
    "\n",
    "        clf.fit(train.drop(columns=[check_disorder]), train[check_disorder])\n",
    "        preds = clf.predict(test.drop(columns=[check_disorder]))\n",
    "        y_test = test[check_disorder]\n",
    "\n",
    "        print('================================= {0} ================================='.format(check_disorder))\n",
    "\n",
    "        precision, recall, _, _ = precision_recall_fscore_support(y_test, preds)\n",
    "        accuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "        print('accuracy {:.3f} precision {:.3f} {:.3f} recall {:.3f} {:.3f}' \\\n",
    "              .format(accuracy, precision[0], precision[1], recall[0], recall[1]))\n",
    "\n",
    "        print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st approach: Do nothing\n",
    "\n",
    "Some algorithms such as XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= Neurodevelopmental Disorders =================================\n",
      "accuracy 0.819 precision 0.657 0.858 recall 0.532 0.911\n",
      "[[ 67  59]\n",
      " [ 35 357]]\n"
     ]
    }
   ],
   "source": [
    "def do_nothing(x, y):\n",
    "    return x, y\n",
    "\n",
    "run_binary_classification(processed, 1, xgb.XGBClassifier(), do_nothing, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd approach: Fill all missing values with a dummy value \n",
    "\n",
    "(For this refer to @gvasilak 's notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd approach: Imputation Using (Mean/Median/Most_frequent) Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= Neurodevelopmental Disorders =================================\n",
      "accuracy 0.807 precision 0.681 0.827 recall 0.389 0.941\n",
      "[[ 49  77]\n",
      " [ 23 369]]\n"
     ]
    }
   ],
   "source": [
    "strategy = 'median'\n",
    "assert strategy in ['mean', 'median', 'most_frequent']\n",
    "\n",
    "def imputer(x, y, strategy):\n",
    "    if strategy == 'mean':\n",
    "        filling = x.mean()\n",
    "    elif strategy == 'median':\n",
    "        filling = x.median()\n",
    "    elif strategy == 'most_frequent':\n",
    "        filling = x.mode().iloc[0]\n",
    "    \n",
    "    return x.fillna(filling), y.fillna(filling)\n",
    "\n",
    "clf = RandomForestClassifier(class_weight='balanced', n_estimators=100)\n",
    "run_binary_classification(processed, 1, clf, imputer, False, strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4th approach: Imputation Using k-NN\n",
    "\n",
    "The algorithm uses ‘feature similarity’ to predict the values of any new data points. This means that the new point is assigned a value based on how closely it resembles the points in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.setrecursionlimit(100000) #Increase the recursion limit of the OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "BadInputError",
     "evalue": "No NaN's in given data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadInputError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-b5551b1ceb85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# start the KNN training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimputed_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfast_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/impyute/util/preprocess.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpd_DataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/impyute/util/checks.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadInputError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data is not float.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_nan_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadInputError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No NaN's in given data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadInputError\u001b[0m: No NaN's in given data"
     ]
    }
   ],
   "source": [
    "# start the KNN training\n",
    "imputed_training=fast_knn(temp.values, k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = most_common_disorders.index(check_disorder)\n",
    "\n",
    "columns_to_drop = most_common_disorders[:pos] + most_common_disorders[(pos + 1):]\n",
    "\n",
    "temp = processed.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-242520f552cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# start the KNN training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimputed_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfast_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/impyute/util/preprocess.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpd_DataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/impyute/util/checks.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_nan_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadInputError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No NaN's in given data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/impyute/imputation/cs/fast_knn.py\u001b[0m in \u001b[0;36mfast_knn\u001b[0;34m(data, k, eps, p, distance_upper_bound, leafsize, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnull_xy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         distances, indices = kdtree.query(data_c[x_i], k=k+1, eps=eps,\n\u001b[0;32m--> 110\u001b[0;31m                                           p=p, distance_upper_bound=distance_upper_bound)\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;31m# Will always return itself in the first index. Delete it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, x, k, eps, p, distance_upper_bound)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mhits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_upper_bound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistance_upper_bound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36m__query\u001b[0;34m(self, x, k, eps, p, distance_upper_bound)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0;31m# far child might be too far, if so, don't bother pushing it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmin_distance\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mdistance_upper_bound\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mepsfac\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m                     \u001b[0mheappush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start the KNN training\n",
    "imputed_training=fast_knn(temp.values, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5th approach: MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-23978943e709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# start the MICE training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimputed_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/impyute/util/preprocess.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpd_DataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/impyute/util/checks.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_nan_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadInputError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No NaN's in given data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/impyute/imputation/cs/mice.py\u001b[0m in \u001b[0;36mmice\u001b[0;34m(data, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mx_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0my_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my_i\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdependent_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;31m# Row 'x' without the nan value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from impyute.imputation.cs import mice\n",
    "\n",
    "# start the MICE training\n",
    "imputed_training=mice(temp.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6th approach: Add features indicating if the value os misisng or not\n",
    "\n",
    "For this part we should take into account which exact features can have Nan values\n",
    "\n",
    "The features that do not take any null values are 'Sex', 'Age', 'Study.Site' and the disorder we are currently checking for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= Neurodevelopmental Disorders =================================\n",
      "accuracy 0.820 precision 0.739 0.833 recall 0.405 0.954\n",
      "[[ 51  75]\n",
      " [ 18 374]]\n"
     ]
    }
   ],
   "source": [
    "def process_dataset(x, cols):\n",
    "    x1 = x.drop(columns=cols).isna().astype('int32')\n",
    "    \n",
    "    # change column naming to enable the inner join\n",
    "    x1.columns = [col + '_existence' for col in x1.columns]\n",
    "    return x1.join(x)\n",
    "\n",
    "def data_and_existence_of_features(x, y, disorder):\n",
    "    cols = ['Sex', 'Age', 'Study.Site', disorder]\n",
    "    rest_of_columns = list(x.columns.values)\n",
    "    for c in cols:\n",
    "        rest_of_columns.remove(c)\n",
    "    \n",
    "    x_new = process_dataset(x, cols)\n",
    "    y_new = process_dataset(y, cols)\n",
    "    \n",
    "    x_new[rest_of_columns], y_new[rest_of_columns] = imputer(x_new[rest_of_columns], \n",
    "                                                             y_new[rest_of_columns], \n",
    "                                                             'most_frequent')\n",
    "    return x_new, y_new\n",
    "\n",
    "run_binary_classification(processed, 1, clf, data_and_existence_of_features, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existence of features\n",
    "\n",
    "To explore the severity of existence of a feature for the correct classification, we only try to predict based on the existence of the features only and not the actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= Neurodevelopmental Disorders =================================\n",
      "accuracy 0.720 precision 0.398 0.791 recall 0.294 0.857\n",
      "[[ 37  89]\n",
      " [ 56 336]]\n"
     ]
    }
   ],
   "source": [
    "def process_dataset_only_existence(x, cols):\n",
    "    x1 = x.drop(columns=cols).isna().astype('int32')\n",
    "    x2 = x[cols]\n",
    "    \n",
    "    return x1.join(x2)\n",
    "\n",
    "def only_existence_of_features(x, y, disorder):\n",
    "    cols = ['Sex', 'Age', 'Study.Site', disorder]\n",
    "    return process_dataset_only_existence(x, cols), process_dataset_only_existence(y, cols)\n",
    "\n",
    "run_binary_classification(processed, 1, clf, only_existence_of_features, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
